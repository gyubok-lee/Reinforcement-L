{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27f7bb95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25.2\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install --upgrade gym==0.25.2\n",
    "import gym\n",
    "print (gym.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd91d4d",
   "metadata": {},
   "source": [
    "# A2C_PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "194794b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:23: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  serialized_pb=_b('\\n,tensorflow/core/framework/tensor_shape.proto\\x12\\ntensorflow\\\"z\\n\\x10TensorShapeProto\\x12-\\n\\x03\\x64im\\x18\\x02 \\x03(\\x0b\\x32 .tensorflow.TensorShapeProto.Dim\\x12\\x14\\n\\x0cunknown_rank\\x18\\x03 \\x01(\\x08\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01 \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tB\\x87\\x01\\n\\x18org.tensorflow.frameworkB\\x11TensorShapeProtosP\\x01ZSgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\\xf8\\x01\\x01\\x62\\x06proto3')\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:42: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  serialized_options=None, file=DESCRIPTOR),\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:63: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  serialized_end=182,\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:24: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  serialized_pb=_b('\\n%tensorflow/core/framework/types.proto\\x12\\ntensorflow*\\xaa\\x06\\n\\x08\\x44\\x61taType\\x12\\x0e\\n\\nDT_INVALID\\x10\\x00\\x12\\x0c\\n\\x08\\x44T_FLOAT\\x10\\x01\\x12\\r\\n\\tDT_DOUBLE\\x10\\x02\\x12\\x0c\\n\\x08\\x44T_INT32\\x10\\x03\\x12\\x0c\\n\\x08\\x44T_UINT8\\x10\\x04\\x12\\x0c\\n\\x08\\x44T_INT16\\x10\\x05\\x12\\x0b\\n\\x07\\x44T_INT8\\x10\\x06\\x12\\r\\n\\tDT_STRING\\x10\\x07\\x12\\x10\\n\\x0c\\x44T_COMPLEX64\\x10\\x08\\x12\\x0c\\n\\x08\\x44T_INT64\\x10\\t\\x12\\x0b\\n\\x07\\x44T_BOOL\\x10\\n\\x12\\x0c\\n\\x08\\x44T_QINT8\\x10\\x0b\\x12\\r\\n\\tDT_QUINT8\\x10\\x0c\\x12\\r\\n\\tDT_QINT32\\x10\\r\\x12\\x0f\\n\\x0b\\x44T_BFLOAT16\\x10\\x0e\\x12\\r\\n\\tDT_QINT16\\x10\\x0f\\x12\\x0e\\n\\nDT_QUINT16\\x10\\x10\\x12\\r\\n\\tDT_UINT16\\x10\\x11\\x12\\x11\\n\\rDT_COMPLEX128\\x10\\x12\\x12\\x0b\\n\\x07\\x44T_HALF\\x10\\x13\\x12\\x0f\\n\\x0b\\x44T_RESOURCE\\x10\\x14\\x12\\x0e\\n\\nDT_VARIANT\\x10\\x15\\x12\\r\\n\\tDT_UINT32\\x10\\x16\\x12\\r\\n\\tDT_UINT64\\x10\\x17\\x12\\x10\\n\\x0c\\x44T_FLOAT_REF\\x10\\x65\\x12\\x11\\n\\rDT_DOUBLE_REF\\x10\\x66\\x12\\x10\\n\\x0c\\x44T_INT32_REF\\x10g\\x12\\x10\\n\\x0c\\x44T_UINT8_REF\\x10h\\x12\\x10\\n\\x0c\\x44T_INT16_REF\\x10i\\x12\\x0f\\n\\x0b\\x44T_INT8_REF\\x10j\\x12\\x11\\n\\rDT_STRING_REF\\x10k\\x12\\x14\\n\\x10\\x44T_COMPLEX64_REF\\x10l\\x12\\x10\\n\\x0c\\x44T_INT64_REF\\x10m\\x12\\x0f\\n\\x0b\\x44T_BOOL_REF\\x10n\\x12\\x10\\n\\x0c\\x44T_QINT8_REF\\x10o\\x12\\x11\\n\\rDT_QUINT8_REF\\x10p\\x12\\x11\\n\\rDT_QINT32_REF\\x10q\\x12\\x13\\n\\x0f\\x44T_BFLOAT16_REF\\x10r\\x12\\x11\\n\\rDT_QINT16_REF\\x10s\\x12\\x12\\n\\x0e\\x44T_QUINT16_REF\\x10t\\x12\\x11\\n\\rDT_UINT16_REF\\x10u\\x12\\x15\\n\\x11\\x44T_COMPLEX128_REF\\x10v\\x12\\x0f\\n\\x0b\\x44T_HALF_REF\\x10w\\x12\\x13\\n\\x0f\\x44T_RESOURCE_REF\\x10x\\x12\\x12\\n\\x0e\\x44T_VARIANT_REF\\x10y\\x12\\x11\\n\\rDT_UINT32_REF\\x10z\\x12\\x11\\n\\rDT_UINT64_REF\\x10{*F\\n\\x0fSpecializedType\\x12\\x0e\\n\\nST_INVALID\\x10\\x00\\x12\\x12\\n\\x0eST_TENSOR_LIST\\x10\\x01\\x12\\x0f\\n\\x0bST_OPTIONAL\\x10\\x02\\x42z\\n\\x18org.tensorflow.frameworkB\\x0bTypesProtosP\\x01ZLgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/types_go_proto\\xf8\\x01\\x01\\x62\\x06proto3')\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:36: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  type=None),\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:225: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  serialized_end=864,\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:27: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  dependencies=[tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2.DESCRIPTOR,tensorflow_dot_core_dot_framework_dot_types__pb2.DESCRIPTOR,])\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:45: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  serialized_options=None, file=DESCRIPTOR),\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:66: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  serialized_end=436,\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:28: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  dependencies=[tensorflow_dot_core_dot_framework_dot_resource__handle__pb2.DESCRIPTOR,tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2.DESCRIPTOR,tensorflow_dot_core_dot_framework_dot_types__pb2.DESCRIPTOR,])\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:46: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  serialized_options=None, file=DESCRIPTOR),\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:172: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  serialized_end=713,\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:28: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  dependencies=[tensorflow_dot_core_dot_framework_dot_tensor__pb2.DESCRIPTOR,tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2.DESCRIPTOR,tensorflow_dot_core_dot_framework_dot_types__pb2.DESCRIPTOR,])\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:46: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  serialized_options=None, file=DESCRIPTOR),\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\core.py:318: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameters\n",
    "gamma = 0.99  # Discount factor for future rewards\n",
    "epsilon = 0.15  # PPO clipping factor\n",
    "actor_lr = 0.0003  # Learning rate for actor\n",
    "critic_lr = 0.001  # Learning rate for critic\n",
    "batch_size = 64  # Batch size for training\n",
    "n_epochs = 10  # Number of epochs per update\n",
    "update_interval = 80000  # Steps between updates\n",
    "\n",
    "# Environment\n",
    "env = gym.make('CartPole-v1')\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "# Actor Model\n",
    "def get_actor():\n",
    "    inputs = layers.Input(shape=(state_dim,))\n",
    "    x = layers.Dense(128, activation=\"relu\")(inputs)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(action_dim, activation=\"softmax\")(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Critic Model\n",
    "def get_critic():\n",
    "    inputs = layers.Input(shape=(state_dim,))\n",
    "    x = layers.Dense(128, activation=\"relu\")(inputs)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "actor = get_actor()\n",
    "critic = get_critic()\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "\n",
    "# Function to get action based on policy\n",
    "def get_action(state):\n",
    "    state = state.reshape([1, state_dim])\n",
    "    prob = actor(state).numpy()\n",
    "    action = np.random.choice(action_dim, p=prob[0])\n",
    "    return action, prob\n",
    "\n",
    "# Function to compute discounted rewards\n",
    "def compute_discounted_rewards(rewards, dones, next_value):\n",
    "    discounted_rewards = []\n",
    "    R = next_value\n",
    "    for reward, done in zip(reversed(rewards), reversed(dones)):\n",
    "        R = reward + gamma * R * (1 - done)\n",
    "        discounted_rewards.insert(0, R)\n",
    "    return discounted_rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7729db4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished with score: 36.0\n",
      "Episode finished with score: 29.0\n",
      "Episode finished with score: 16.0\n",
      "Episode finished with score: 20.0\n",
      "Episode finished with score: 34.0\n",
      "Episode finished with score: 16.0\n",
      "Episode finished with score: 12.0\n",
      "Episode finished with score: 15.0\n",
      "Episode finished with score: 10.0\n",
      "Episode finished with score: 19.0\n",
      "Episode finished with score: 15.0\n",
      "Episode finished with score: 36.0\n",
      "Episode finished with score: 35.0\n",
      "Episode finished with score: 29.0\n",
      "Episode finished with score: 15.0\n",
      "Episode finished with score: 14.0\n",
      "Episode finished with score: 13.0\n",
      "Episode finished with score: 26.0\n",
      "Episode finished with score: 35.0\n",
      "Episode finished with score: 40.0\n",
      "Episode finished with score: 10.0\n",
      "Episode finished with score: 43.0\n",
      "Episode finished with score: 16.0\n",
      "Episode finished with score: 21.0\n",
      "Episode finished with score: 27.0\n",
      "Episode finished with score: 11.0\n",
      "Episode finished with score: 19.0\n",
      "Episode finished with score: 17.0\n",
      "Episode finished with score: 9.0\n",
      "Episode finished with score: 17.0\n",
      "Episode finished with score: 39.0\n",
      "Episode finished with score: 20.0\n",
      "Episode finished with score: 32.0\n",
      "Episode finished with score: 18.0\n",
      "Episode finished with score: 38.0\n",
      "Episode finished with score: 16.0\n",
      "Episode finished with score: 21.0\n",
      "Episode finished with score: 24.0\n",
      "Episode finished with score: 35.0\n",
      "Episode finished with score: 22.0\n",
      "Episode finished with score: 44.0\n",
      "Episode finished with score: 22.0\n",
      "Episode finished with score: 19.0\n",
      "Episode finished with score: 10.0\n",
      "Episode finished with score: 12.0\n",
      "Episode finished with score: 13.0\n",
      "Episode finished with score: 18.0\n",
      "Episode finished with score: 11.0\n",
      "Episode finished with score: 25.0\n",
      "Episode finished with score: 73.0\n",
      "Episode finished with score: 11.0\n",
      "Episode finished with score: 16.0\n",
      "Episode finished with score: 12.0\n",
      "Episode finished with score: 76.0\n",
      "Episode finished with score: 23.0\n",
      "Episode finished with score: 12.0\n",
      "Episode finished with score: 20.0\n",
      "Episode finished with score: 44.0\n",
      "Episode finished with score: 16.0\n",
      "Episode finished with score: 24.0\n",
      "Episode finished with score: 25.0\n",
      "Episode finished with score: 13.0\n",
      "Episode finished with score: 57.0\n",
      "Episode finished with score: 26.0\n",
      "Episode finished with score: 18.0\n",
      "Episode finished with score: 13.0\n",
      "Episode finished with score: 19.0\n",
      "Episode finished with score: 32.0\n",
      "Episode finished with score: 12.0\n",
      "Episode finished with score: 32.0\n",
      "Episode finished with score: 34.0\n",
      "Episode finished with score: 29.0\n",
      "Episode finished with score: 55.0\n",
      "Episode finished with score: 10.0\n",
      "Episode finished with score: 59.0\n",
      "Episode finished with score: 24.0\n",
      "Episode finished with score: 17.0\n",
      "Episode finished with score: 32.0\n",
      "Episode finished with score: 19.0\n",
      "Episode finished with score: 43.0\n",
      "Episode finished with score: 26.0\n",
      "Episode finished with score: 18.0\n",
      "Episode finished with score: 20.0\n",
      "Episode finished with score: 19.0\n",
      "Episode finished with score: 12.0\n",
      "Episode finished with score: 15.0\n",
      "Episode finished with score: 20.0\n",
      "Episode finished with score: 16.0\n",
      "Episode finished with score: 26.0\n",
      "Episode finished with score: 62.0\n",
      "Episode finished with score: 22.0\n",
      "Episode finished with score: 46.0\n",
      "Episode finished with score: 50.0\n",
      "Episode finished with score: 40.0\n",
      "Episode finished with score: 43.0\n",
      "Episode finished with score: 37.0\n",
      "Episode finished with score: 15.0\n",
      "Episode finished with score: 31.0\n",
      "Episode finished with score: 16.0\n",
      "Episode finished with score: 29.0\n",
      "Episode finished with score: 42.0\n",
      "Episode finished with score: 25.0\n",
      "Episode finished with score: 22.0\n",
      "Episode finished with score: 18.0\n",
      "Episode finished with score: 14.0\n",
      "Episode finished with score: 31.0\n",
      "Episode finished with score: 22.0\n",
      "Episode finished with score: 32.0\n",
      "Episode finished with score: 21.0\n",
      "Episode finished with score: 39.0\n",
      "Episode finished with score: 23.0\n",
      "Episode finished with score: 40.0\n",
      "Episode finished with score: 44.0\n",
      "Episode finished with score: 26.0\n",
      "Episode finished with score: 12.0\n",
      "Episode finished with score: 35.0\n",
      "Episode finished with score: 18.0\n",
      "Episode finished with score: 17.0\n",
      "Episode finished with score: 26.0\n",
      "Episode finished with score: 35.0\n",
      "Episode finished with score: 10.0\n",
      "Episode finished with score: 27.0\n",
      "Episode finished with score: 48.0\n",
      "Episode finished with score: 33.0\n",
      "Episode finished with score: 20.0\n",
      "Episode finished with score: 34.0\n",
      "Episode finished with score: 28.0\n",
      "Episode finished with score: 42.0\n",
      "Episode finished with score: 72.0\n",
      "Episode finished with score: 46.0\n",
      "Episode finished with score: 42.0\n",
      "Episode finished with score: 82.0\n",
      "Episode finished with score: 27.0\n",
      "Episode finished with score: 34.0\n",
      "Episode finished with score: 142.0\n",
      "Episode finished with score: 17.0\n",
      "Episode finished with score: 20.0\n",
      "Episode finished with score: 19.0\n",
      "Episode finished with score: 30.0\n",
      "Episode finished with score: 67.0\n",
      "Episode finished with score: 20.0\n",
      "Episode finished with score: 9.0\n",
      "Episode finished with score: 67.0\n",
      "Episode finished with score: 70.0\n",
      "Episode finished with score: 23.0\n",
      "Episode finished with score: 29.0\n",
      "Episode finished with score: 16.0\n",
      "Episode finished with score: 27.0\n",
      "Episode finished with score: 28.0\n",
      "Episode finished with score: 62.0\n",
      "Episode finished with score: 62.0\n",
      "Episode finished with score: 22.0\n",
      "Episode finished with score: 24.0\n",
      "Episode finished with score: 22.0\n",
      "Episode finished with score: 49.0\n",
      "Episode finished with score: 17.0\n",
      "Episode finished with score: 20.0\n",
      "Episode finished with score: 21.0\n",
      "Episode finished with score: 21.0\n",
      "Episode finished with score: 13.0\n",
      "Episode finished with score: 71.0\n",
      "Episode finished with score: 41.0\n",
      "Episode finished with score: 25.0\n",
      "Episode finished with score: 51.0\n",
      "Episode finished with score: 30.0\n",
      "Episode finished with score: 23.0\n",
      "Episode finished with score: 33.0\n",
      "Episode finished with score: 26.0\n",
      "Episode finished with score: 13.0\n",
      "Episode finished with score: 94.0\n",
      "Episode finished with score: 71.0\n",
      "Episode finished with score: 20.0\n",
      "Episode finished with score: 44.0\n",
      "Episode finished with score: 38.0\n",
      "Episode finished with score: 26.0\n",
      "Episode finished with score: 24.0\n",
      "Episode finished with score: 35.0\n",
      "Episode finished with score: 16.0\n",
      "Episode finished with score: 31.0\n",
      "Episode finished with score: 13.0\n",
      "Episode finished with score: 49.0\n",
      "Episode finished with score: 129.0\n",
      "Episode finished with score: 43.0\n",
      "Episode finished with score: 50.0\n",
      "Episode finished with score: 17.0\n",
      "Episode finished with score: 46.0\n",
      "Episode finished with score: 79.0\n",
      "Episode finished with score: 40.0\n",
      "Episode finished with score: 66.0\n",
      "Episode finished with score: 28.0\n",
      "Episode finished with score: 144.0\n",
      "Episode finished with score: 40.0\n",
      "Episode finished with score: 17.0\n",
      "Episode finished with score: 76.0\n",
      "Episode finished with score: 41.0\n",
      "Episode finished with score: 45.0\n",
      "Episode finished with score: 80.0\n",
      "Episode finished with score: 39.0\n",
      "Episode finished with score: 27.0\n",
      "Episode finished with score: 34.0\n",
      "Episode finished with score: 24.0\n",
      "Episode finished with score: 102.0\n",
      "Episode finished with score: 28.0\n",
      "Episode finished with score: 19.0\n",
      "Episode finished with score: 27.0\n",
      "Episode finished with score: 16.0\n",
      "Episode finished with score: 21.0\n",
      "Episode finished with score: 54.0\n",
      "Episode finished with score: 23.0\n",
      "Episode finished with score: 44.0\n",
      "Episode finished with score: 98.0\n",
      "Episode finished with score: 24.0\n",
      "Episode finished with score: 35.0\n",
      "Episode finished with score: 56.0\n",
      "Episode finished with score: 34.0\n",
      "Episode finished with score: 22.0\n",
      "Episode finished with score: 17.0\n",
      "Episode finished with score: 16.0\n",
      "Episode finished with score: 69.0\n",
      "Episode finished with score: 26.0\n",
      "Episode finished with score: 61.0\n",
      "Episode finished with score: 74.0\n",
      "Episode finished with score: 143.0\n",
      "Episode finished with score: 44.0\n",
      "Episode finished with score: 87.0\n",
      "Episode finished with score: 95.0\n",
      "Episode finished with score: 81.0\n",
      "Episode finished with score: 71.0\n",
      "Episode finished with score: 143.0\n",
      "Episode finished with score: 135.0\n",
      "Episode finished with score: 37.0\n",
      "Episode finished with score: 158.0\n",
      "Episode finished with score: 77.0\n",
      "Episode finished with score: 205.0\n",
      "Episode finished with score: 44.0\n",
      "Episode finished with score: 81.0\n",
      "Episode finished with score: 111.0\n",
      "Episode finished with score: 36.0\n",
      "Episode finished with score: 72.0\n",
      "Episode finished with score: 101.0\n",
      "Episode finished with score: 122.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished with score: 230.0\n",
      "Episode finished with score: 73.0\n",
      "Episode finished with score: 50.0\n",
      "Episode finished with score: 54.0\n",
      "Episode finished with score: 89.0\n",
      "Episode finished with score: 118.0\n",
      "Episode finished with score: 112.0\n",
      "Episode finished with score: 210.0\n",
      "Episode finished with score: 94.0\n",
      "Episode finished with score: 112.0\n",
      "Episode finished with score: 163.0\n",
      "Episode finished with score: 113.0\n",
      "Episode finished with score: 36.0\n",
      "Episode finished with score: 143.0\n",
      "Episode finished with score: 59.0\n",
      "Episode finished with score: 201.0\n",
      "Episode finished with score: 152.0\n",
      "Episode finished with score: 199.0\n",
      "Episode finished with score: 151.0\n",
      "Episode finished with score: 133.0\n",
      "Episode finished with score: 148.0\n",
      "Episode finished with score: 119.0\n",
      "Episode finished with score: 152.0\n",
      "Episode finished with score: 273.0\n",
      "Episode finished with score: 170.0\n",
      "Episode finished with score: 184.0\n",
      "Episode finished with score: 122.0\n",
      "Episode finished with score: 122.0\n",
      "Episode finished with score: 49.0\n",
      "Episode finished with score: 111.0\n",
      "Episode finished with score: 106.0\n",
      "Episode finished with score: 107.0\n",
      "Episode finished with score: 150.0\n",
      "Episode finished with score: 261.0\n",
      "Episode finished with score: 222.0\n",
      "Episode finished with score: 269.0\n",
      "Episode finished with score: 109.0\n",
      "Episode finished with score: 414.0\n",
      "Episode finished with score: 111.0\n",
      "Episode finished with score: 192.0\n",
      "Episode finished with score: 130.0\n",
      "Episode finished with score: 125.0\n",
      "Episode finished with score: 179.0\n",
      "Episode finished with score: 118.0\n",
      "Episode finished with score: 112.0\n",
      "Episode finished with score: 162.0\n",
      "Episode finished with score: 180.0\n",
      "Episode finished with score: 145.0\n",
      "Episode finished with score: 326.0\n",
      "Episode finished with score: 279.0\n",
      "Episode finished with score: 209.0\n",
      "Episode finished with score: 84.0\n",
      "Episode finished with score: 450.0\n",
      "Episode finished with score: 260.0\n",
      "Episode finished with score: 167.0\n",
      "Episode finished with score: 125.0\n",
      "Episode finished with score: 234.0\n",
      "Episode finished with score: 136.0\n",
      "Episode finished with score: 292.0\n",
      "Episode finished with score: 262.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 124.0\n",
      "Episode finished with score: 157.0\n",
      "Episode finished with score: 138.0\n",
      "Episode finished with score: 219.0\n",
      "Episode finished with score: 159.0\n",
      "Episode finished with score: 143.0\n",
      "Episode finished with score: 113.0\n",
      "Episode finished with score: 123.0\n",
      "Episode finished with score: 196.0\n",
      "Episode finished with score: 183.0\n",
      "Episode finished with score: 171.0\n",
      "Episode finished with score: 131.0\n",
      "Episode finished with score: 181.0\n",
      "Episode finished with score: 128.0\n",
      "Episode finished with score: 317.0\n",
      "Episode finished with score: 389.0\n",
      "Episode finished with score: 216.0\n",
      "Episode finished with score: 247.0\n",
      "Episode finished with score: 436.0\n",
      "Episode finished with score: 427.0\n",
      "Episode finished with score: 248.0\n",
      "Episode finished with score: 201.0\n",
      "Episode finished with score: 213.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 273.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 237.0\n",
      "Episode finished with score: 162.0\n",
      "Episode finished with score: 364.0\n",
      "Episode finished with score: 148.0\n",
      "Episode finished with score: 315.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 317.0\n",
      "Episode finished with score: 97.0\n",
      "Episode finished with score: 296.0\n",
      "Episode finished with score: 193.0\n",
      "Episode finished with score: 198.0\n",
      "Episode finished with score: 223.0\n",
      "Episode finished with score: 312.0\n",
      "Episode finished with score: 183.0\n",
      "Episode finished with score: 126.0\n",
      "Episode finished with score: 224.0\n",
      "Episode finished with score: 181.0\n",
      "Episode finished with score: 171.0\n",
      "Episode finished with score: 34.0\n",
      "Episode finished with score: 116.0\n",
      "Episode finished with score: 117.0\n",
      "Episode finished with score: 125.0\n",
      "Episode finished with score: 135.0\n",
      "Episode finished with score: 290.0\n",
      "Episode finished with score: 179.0\n",
      "Episode finished with score: 159.0\n",
      "Episode finished with score: 132.0\n",
      "Episode finished with score: 434.0\n",
      "Episode finished with score: 112.0\n",
      "Episode finished with score: 434.0\n",
      "Episode finished with score: 143.0\n",
      "Episode finished with score: 378.0\n",
      "Episode finished with score: 133.0\n",
      "Episode finished with score: 273.0\n",
      "Episode finished with score: 397.0\n",
      "Episode finished with score: 164.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 439.0\n",
      "Episode finished with score: 255.0\n",
      "Episode finished with score: 395.0\n",
      "Episode finished with score: 210.0\n",
      "Episode finished with score: 469.0\n",
      "Episode finished with score: 174.0\n",
      "Episode finished with score: 320.0\n",
      "Episode finished with score: 142.0\n",
      "Episode finished with score: 268.0\n",
      "Episode finished with score: 174.0\n",
      "Episode finished with score: 271.0\n",
      "Episode finished with score: 476.0\n",
      "Episode finished with score: 204.0\n",
      "Episode finished with score: 261.0\n",
      "Episode finished with score: 235.0\n",
      "Episode finished with score: 265.0\n",
      "Episode finished with score: 155.0\n",
      "Episode finished with score: 225.0\n",
      "Episode finished with score: 216.0\n",
      "Episode finished with score: 178.0\n",
      "Episode finished with score: 151.0\n",
      "Episode finished with score: 115.0\n",
      "Episode finished with score: 237.0\n",
      "Episode finished with score: 409.0\n",
      "Episode finished with score: 302.0\n",
      "Episode finished with score: 165.0\n",
      "Episode finished with score: 307.0\n",
      "Episode finished with score: 289.0\n",
      "Episode finished with score: 301.0\n",
      "Episode finished with score: 490.0\n",
      "Episode finished with score: 256.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 426.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 224.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 497.0\n",
      "Episode finished with score: 302.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 167.0\n",
      "Episode finished with score: 468.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 332.0\n",
      "Episode finished with score: 191.0\n",
      "Episode finished with score: 232.0\n",
      "Episode finished with score: 236.0\n",
      "Episode finished with score: 278.0\n",
      "Episode finished with score: 290.0\n",
      "Episode finished with score: 334.0\n",
      "Episode finished with score: 273.0\n",
      "Episode finished with score: 259.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 134.0\n",
      "Episode finished with score: 380.0\n",
      "Episode finished with score: 146.0\n",
      "Episode finished with score: 129.0\n",
      "Episode finished with score: 169.0\n",
      "Episode finished with score: 102.0\n",
      "Episode finished with score: 231.0\n",
      "Episode finished with score: 276.0\n",
      "Episode finished with score: 195.0\n",
      "Episode finished with score: 310.0\n",
      "Episode finished with score: 314.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 231.0\n",
      "Episode finished with score: 212.0\n",
      "Episode finished with score: 218.0\n",
      "Episode finished with score: 447.0\n",
      "Episode finished with score: 340.0\n",
      "Episode finished with score: 195.0\n",
      "Episode finished with score: 494.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 406.0\n",
      "Episode finished with score: 264.0\n",
      "Episode finished with score: 270.0\n",
      "Episode finished with score: 265.0\n",
      "Episode finished with score: 307.0\n",
      "Episode finished with score: 168.0\n",
      "Episode finished with score: 286.0\n",
      "Episode finished with score: 266.0\n",
      "Episode finished with score: 181.0\n",
      "Episode finished with score: 215.0\n",
      "Episode finished with score: 190.0\n",
      "Episode finished with score: 130.0\n",
      "Episode finished with score: 192.0\n",
      "Episode finished with score: 194.0\n",
      "Episode finished with score: 173.0\n",
      "Episode finished with score: 136.0\n",
      "Episode finished with score: 389.0\n",
      "Episode finished with score: 172.0\n",
      "Episode finished with score: 163.0\n",
      "Episode finished with score: 135.0\n",
      "Episode finished with score: 227.0\n",
      "Episode finished with score: 317.0\n",
      "Episode finished with score: 177.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 178.0\n",
      "Episode finished with score: 331.0\n",
      "Episode finished with score: 308.0\n",
      "Episode finished with score: 309.0\n",
      "Episode finished with score: 231.0\n",
      "Episode finished with score: 187.0\n",
      "Episode finished with score: 171.0\n",
      "Episode finished with score: 137.0\n",
      "Episode finished with score: 150.0\n",
      "Episode finished with score: 213.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished with score: 252.0\n",
      "Episode finished with score: 331.0\n",
      "Episode finished with score: 169.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 350.0\n",
      "Episode finished with score: 275.0\n",
      "Episode finished with score: 209.0\n",
      "Episode finished with score: 435.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 360.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 295.0\n",
      "Episode finished with score: 295.0\n",
      "Episode finished with score: 143.0\n",
      "Episode finished with score: 393.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 229.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 343.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 339.0\n",
      "Episode finished with score: 432.0\n",
      "Episode finished with score: 455.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 496.0\n",
      "Episode finished with score: 500.0\n",
      "Episode finished with score: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training loop with reward tracking\n",
    "state = env.reset()\n",
    "states, actions, rewards, probs, dones = [], [], [], [], []\n",
    "scores = []\n",
    "episode_rewards = []\n",
    "score = 0\n",
    "\n",
    "for step in range(1, update_interval + 1): # 1. 학습할 총 스텝수마다\n",
    "    action, prob = get_action(state) # 2. 확률공간에 기반하여 행동 선택\n",
    "    next_state, reward, done, _ = env.step(action) # 3. 행동 후 상태 업데이트\n",
    "\n",
    "    states.append(state)\n",
    "    actions.append(action)\n",
    "    rewards.append(reward)\n",
    "    probs.append(prob[0, action])\n",
    "    dones.append(done)\n",
    "\n",
    "    state = next_state\n",
    "    score += reward\n",
    "\n",
    "    if done:\n",
    "        episode_rewards.append(score)\n",
    "        state = env.reset()\n",
    "        print(f\"Episode finished with score: {score}\")\n",
    "        score = 0\n",
    "\n",
    "    if step % batch_size == 0: # 4. 배치 사이즈마다\n",
    "        states = np.array(states)\n",
    "        actions = np.array(actions)\n",
    "        rewards = np.array(rewards)\n",
    "        probs = np.array(probs)\n",
    "        dones = np.array(dones)\n",
    "\n",
    "        # Compute next value from critic\n",
    "        next_value = critic(np.array([next_state]))[0, 0] # 5. 비평가 네트워크에서 다음 가치(할인 적용) 예측\n",
    "        discounted_rewards = compute_discounted_rewards(rewards, dones, next_value) # 할인 적용\n",
    "\n",
    "        discounted_rewards = np.array(discounted_rewards)\n",
    "        values = critic(states).numpy().flatten()\n",
    "        advantages = discounted_rewards - values # 6. 이익계산\n",
    "\n",
    "        with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
    "            # 7. 행동자 업데이트 : clip을 적용하여 행동의 확률공간을 업데이트 -> 현재 정책(가능한 모든 경우의 수에 대한 기대가치)을 최적화\n",
    "            # 지금의 상황의 가치를 평가한다는 것은 곧 모든 가능한 행동의 확률공간이 유리하다는 것. \n",
    "            action_masks = tf.one_hot(actions, action_dim)\n",
    "            log_probs = tf.reduce_sum(action_masks * tf.math.log(actor(states)), axis=1)\n",
    "            old_log_probs = tf.math.log(probs)\n",
    "            ratios = tf.exp(log_probs - old_log_probs)\n",
    "            clipped_ratios = tf.clip_by_value(ratios, 1 - epsilon, 1 + epsilon)\n",
    "            actor_loss = -tf.reduce_mean(tf.minimum(ratios * advantages, clipped_ratios * advantages))\n",
    "\n",
    "            # 7. 비평가 업데이트 : 선택한 행동에 의한 결과의 가치가 계산된 가치와 근접하도록 최적화\n",
    "            critic_loss = tf.reduce_mean(tf.square(discounted_rewards - critic(states)))\n",
    "\n",
    "        # Update actor and critic networks\n",
    "        actor_grads = tape1.gradient(actor_loss, actor.trainable_variables)\n",
    "        critic_grads = tape2.gradient(critic_loss, critic.trainable_variables)\n",
    "        actor_optimizer.apply_gradients(zip(actor_grads, actor.trainable_variables))\n",
    "        critic_optimizer.apply_gradients(zip(critic_grads, critic.trainable_variables))\n",
    "\n",
    "        states, actions, rewards, probs, dones = [], [], [], [], []\n",
    "\n",
    "# Plotting the episode rewards\n",
    "plt.plot(episode_rewards)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Rewards')\n",
    "plt.title('PPO Training Performance')\n",
    "plt.show()\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cccbff",
   "metadata": {},
   "source": [
    "# Double DQN with PER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b3f5cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\core.py:318: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:122: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Total Reward: 13.0\n",
      "Episode: 1, Total Reward: 16.0\n",
      "Episode: 2, Total Reward: 15.0\n",
      "Episode: 3, Total Reward: 9.0\n",
      "Episode: 4, Total Reward: 19.0\n",
      "Episode: 5, Total Reward: 21.0\n",
      "Episode: 6, Total Reward: 12.0\n",
      "Episode: 7, Total Reward: 18.0\n",
      "Episode: 8, Total Reward: 15.0\n",
      "Episode: 9, Total Reward: 17.0\n",
      "Episode: 10, Total Reward: 15.0\n",
      "Episode: 11, Total Reward: 18.0\n",
      "Episode: 12, Total Reward: 12.0\n",
      "Episode: 13, Total Reward: 13.0\n",
      "Episode: 14, Total Reward: 41.0\n",
      "Episode: 15, Total Reward: 25.0\n",
      "Episode: 16, Total Reward: 14.0\n",
      "Episode: 17, Total Reward: 18.0\n",
      "Episode: 18, Total Reward: 17.0\n",
      "Episode: 19, Total Reward: 18.0\n",
      "Episode: 20, Total Reward: 12.0\n",
      "Episode: 21, Total Reward: 11.0\n",
      "Episode: 22, Total Reward: 18.0\n",
      "Episode: 23, Total Reward: 22.0\n",
      "Episode: 24, Total Reward: 16.0\n",
      "Episode: 25, Total Reward: 14.0\n",
      "Episode: 26, Total Reward: 11.0\n",
      "Episode: 27, Total Reward: 11.0\n",
      "Episode: 28, Total Reward: 20.0\n",
      "Episode: 29, Total Reward: 19.0\n",
      "Episode: 30, Total Reward: 22.0\n",
      "Episode: 31, Total Reward: 11.0\n",
      "Episode: 32, Total Reward: 14.0\n",
      "Episode: 33, Total Reward: 18.0\n",
      "Episode: 34, Total Reward: 18.0\n",
      "Episode: 35, Total Reward: 13.0\n",
      "Episode: 36, Total Reward: 28.0\n",
      "Episode: 37, Total Reward: 20.0\n",
      "Episode: 38, Total Reward: 15.0\n",
      "Episode: 39, Total Reward: 18.0\n",
      "Episode: 40, Total Reward: 27.0\n",
      "Episode: 41, Total Reward: 16.0\n",
      "Episode: 42, Total Reward: 11.0\n",
      "Episode: 43, Total Reward: 16.0\n",
      "Episode: 44, Total Reward: 11.0\n",
      "Episode: 45, Total Reward: 12.0\n",
      "Episode: 46, Total Reward: 16.0\n",
      "Episode: 47, Total Reward: 16.0\n",
      "Episode: 48, Total Reward: 11.0\n",
      "Episode: 49, Total Reward: 11.0\n",
      "Episode: 50, Total Reward: 17.0\n",
      "Episode: 51, Total Reward: 13.0\n",
      "Episode: 52, Total Reward: 13.0\n",
      "Episode: 53, Total Reward: 21.0\n",
      "Episode: 54, Total Reward: 29.0\n",
      "Episode: 55, Total Reward: 59.0\n",
      "Episode: 56, Total Reward: 39.0\n",
      "Episode: 57, Total Reward: 70.0\n",
      "Episode: 58, Total Reward: 85.0\n",
      "Episode: 59, Total Reward: 15.0\n",
      "Episode: 60, Total Reward: 19.0\n",
      "Episode: 61, Total Reward: 19.0\n",
      "Episode: 62, Total Reward: 20.0\n",
      "Episode: 63, Total Reward: 54.0\n",
      "Episode: 64, Total Reward: 35.0\n",
      "Episode: 65, Total Reward: 29.0\n",
      "Episode: 66, Total Reward: 23.0\n",
      "Episode: 67, Total Reward: 28.0\n",
      "Episode: 68, Total Reward: 160.0\n",
      "Episode: 69, Total Reward: 33.0\n",
      "Episode: 70, Total Reward: 59.0\n",
      "Episode: 71, Total Reward: 14.0\n",
      "Episode: 72, Total Reward: 120.0\n",
      "Episode: 73, Total Reward: 74.0\n",
      "Episode: 74, Total Reward: 111.0\n",
      "Episode: 75, Total Reward: 99.0\n",
      "Episode: 76, Total Reward: 46.0\n",
      "Episode: 77, Total Reward: 170.0\n",
      "Episode: 78, Total Reward: 139.0\n",
      "Episode: 79, Total Reward: 90.0\n",
      "Episode: 80, Total Reward: 148.0\n",
      "Episode: 81, Total Reward: 161.0\n",
      "Episode: 82, Total Reward: 170.0\n",
      "Episode: 83, Total Reward: 27.0\n",
      "Episode: 84, Total Reward: 51.0\n",
      "Episode: 85, Total Reward: 176.0\n",
      "Episode: 86, Total Reward: 141.0\n",
      "Episode: 87, Total Reward: 82.0\n",
      "Episode: 88, Total Reward: 127.0\n",
      "Episode: 89, Total Reward: 160.0\n",
      "Episode: 90, Total Reward: 153.0\n",
      "Episode: 91, Total Reward: 204.0\n",
      "Episode: 92, Total Reward: 235.0\n",
      "Episode: 93, Total Reward: 168.0\n",
      "Episode: 94, Total Reward: 127.0\n",
      "Episode: 95, Total Reward: 130.0\n",
      "Episode: 96, Total Reward: 271.0\n",
      "Episode: 97, Total Reward: 94.0\n",
      "Episode: 98, Total Reward: 138.0\n",
      "Episode: 99, Total Reward: 156.0\n",
      "Episode: 100, Total Reward: 215.0\n",
      "Episode: 101, Total Reward: 163.0\n",
      "Episode: 102, Total Reward: 193.0\n",
      "Episode: 103, Total Reward: 372.0\n",
      "Episode: 104, Total Reward: 220.0\n",
      "Episode: 105, Total Reward: 240.0\n",
      "Episode: 106, Total Reward: 191.0\n",
      "Episode: 107, Total Reward: 224.0\n",
      "Episode: 108, Total Reward: 100.0\n",
      "Episode: 109, Total Reward: 178.0\n",
      "Episode: 110, Total Reward: 68.0\n",
      "Episode: 111, Total Reward: 282.0\n",
      "Episode: 112, Total Reward: 283.0\n",
      "Episode: 113, Total Reward: 148.0\n",
      "Episode: 114, Total Reward: 138.0\n",
      "Episode: 115, Total Reward: 146.0\n",
      "Episode: 116, Total Reward: 109.0\n",
      "Episode: 117, Total Reward: 144.0\n",
      "Episode: 118, Total Reward: 60.0\n",
      "Episode: 119, Total Reward: 326.0\n",
      "Episode: 120, Total Reward: 125.0\n",
      "Episode: 121, Total Reward: 67.0\n",
      "Episode: 122, Total Reward: 176.0\n",
      "Episode: 123, Total Reward: 127.0\n",
      "Episode: 124, Total Reward: 121.0\n",
      "Episode: 125, Total Reward: 24.0\n",
      "Episode: 126, Total Reward: 140.0\n",
      "Episode: 127, Total Reward: 134.0\n",
      "Episode: 128, Total Reward: 119.0\n",
      "Episode: 129, Total Reward: 117.0\n",
      "Episode: 130, Total Reward: 169.0\n",
      "Episode: 131, Total Reward: 54.0\n",
      "Episode: 132, Total Reward: 122.0\n",
      "Episode: 133, Total Reward: 120.0\n",
      "Episode: 134, Total Reward: 117.0\n",
      "Episode: 135, Total Reward: 117.0\n",
      "Episode: 136, Total Reward: 18.0\n",
      "Episode: 137, Total Reward: 124.0\n",
      "Episode: 138, Total Reward: 101.0\n",
      "Episode: 139, Total Reward: 117.0\n",
      "Episode: 140, Total Reward: 109.0\n",
      "Episode: 141, Total Reward: 201.0\n",
      "Episode: 142, Total Reward: 124.0\n",
      "Episode: 143, Total Reward: 126.0\n",
      "Episode: 144, Total Reward: 119.0\n",
      "Episode: 145, Total Reward: 141.0\n",
      "Episode: 146, Total Reward: 139.0\n",
      "Episode: 147, Total Reward: 270.0\n",
      "Episode: 148, Total Reward: 101.0\n",
      "Episode: 149, Total Reward: 21.0\n",
      "Episode: 150, Total Reward: 140.0\n",
      "Episode: 151, Total Reward: 35.0\n",
      "Episode: 152, Total Reward: 75.0\n",
      "Episode: 153, Total Reward: 19.0\n",
      "Episode: 154, Total Reward: 126.0\n",
      "Episode: 155, Total Reward: 140.0\n",
      "Episode: 156, Total Reward: 264.0\n",
      "Episode: 157, Total Reward: 32.0\n",
      "Episode: 158, Total Reward: 144.0\n",
      "Episode: 159, Total Reward: 147.0\n",
      "Episode: 160, Total Reward: 133.0\n",
      "Episode: 161, Total Reward: 159.0\n",
      "Episode: 162, Total Reward: 124.0\n",
      "Episode: 163, Total Reward: 135.0\n",
      "Episode: 164, Total Reward: 124.0\n",
      "Episode: 165, Total Reward: 125.0\n",
      "Episode: 166, Total Reward: 20.0\n",
      "Episode: 167, Total Reward: 215.0\n",
      "Episode: 168, Total Reward: 17.0\n",
      "Episode: 169, Total Reward: 147.0\n",
      "Episode: 170, Total Reward: 190.0\n",
      "Episode: 171, Total Reward: 288.0\n",
      "Episode: 172, Total Reward: 221.0\n",
      "Episode: 173, Total Reward: 212.0\n",
      "Episode: 174, Total Reward: 23.0\n",
      "Episode: 175, Total Reward: 182.0\n",
      "Episode: 176, Total Reward: 190.0\n",
      "Episode: 177, Total Reward: 182.0\n",
      "Episode: 178, Total Reward: 159.0\n",
      "Episode: 179, Total Reward: 217.0\n",
      "Episode: 180, Total Reward: 166.0\n",
      "Episode: 181, Total Reward: 14.0\n",
      "Episode: 182, Total Reward: 118.0\n",
      "Episode: 183, Total Reward: 14.0\n",
      "Episode: 184, Total Reward: 193.0\n",
      "Episode: 185, Total Reward: 225.0\n",
      "Episode: 186, Total Reward: 181.0\n",
      "Episode: 187, Total Reward: 174.0\n",
      "Episode: 188, Total Reward: 187.0\n",
      "Episode: 189, Total Reward: 14.0\n",
      "Episode: 190, Total Reward: 195.0\n",
      "Episode: 191, Total Reward: 171.0\n",
      "Episode: 192, Total Reward: 95.0\n",
      "Episode: 193, Total Reward: 230.0\n",
      "Episode: 194, Total Reward: 206.0\n",
      "Episode: 195, Total Reward: 195.0\n",
      "Episode: 196, Total Reward: 183.0\n",
      "Episode: 197, Total Reward: 54.0\n",
      "Episode: 198, Total Reward: 171.0\n",
      "Episode: 199, Total Reward: 133.0\n",
      "Episode: 200, Total Reward: 187.0\n",
      "Episode: 201, Total Reward: 247.0\n",
      "Episode: 202, Total Reward: 78.0\n",
      "Episode: 203, Total Reward: 172.0\n",
      "Episode: 204, Total Reward: 40.0\n",
      "Episode: 205, Total Reward: 204.0\n",
      "Episode: 206, Total Reward: 212.0\n",
      "Episode: 207, Total Reward: 53.0\n",
      "Episode: 208, Total Reward: 192.0\n",
      "Episode: 209, Total Reward: 199.0\n",
      "Episode: 210, Total Reward: 203.0\n",
      "Episode: 211, Total Reward: 115.0\n",
      "Episode: 212, Total Reward: 189.0\n",
      "Episode: 213, Total Reward: 200.0\n",
      "Episode: 214, Total Reward: 210.0\n",
      "Episode: 215, Total Reward: 276.0\n",
      "Episode: 216, Total Reward: 193.0\n",
      "Episode: 217, Total Reward: 219.0\n",
      "Episode: 218, Total Reward: 219.0\n",
      "Episode: 219, Total Reward: 203.0\n",
      "Episode: 220, Total Reward: 317.0\n",
      "Episode: 221, Total Reward: 208.0\n",
      "Episode: 222, Total Reward: 212.0\n",
      "Episode: 223, Total Reward: 203.0\n",
      "Episode: 224, Total Reward: 18.0\n",
      "Episode: 225, Total Reward: 261.0\n",
      "Episode: 226, Total Reward: 206.0\n",
      "Episode: 227, Total Reward: 349.0\n",
      "Episode: 228, Total Reward: 317.0\n",
      "Episode: 229, Total Reward: 248.0\n",
      "Episode: 230, Total Reward: 367.0\n",
      "Episode: 231, Total Reward: 246.0\n",
      "Episode: 232, Total Reward: 474.0\n",
      "Episode: 233, Total Reward: 10.0\n",
      "Episode: 234, Total Reward: 223.0\n",
      "Episode: 235, Total Reward: 196.0\n",
      "Episode: 236, Total Reward: 256.0\n",
      "Episode: 237, Total Reward: 14.0\n",
      "Episode: 238, Total Reward: 228.0\n",
      "Episode: 239, Total Reward: 196.0\n",
      "Episode: 240, Total Reward: 456.0\n",
      "Episode: 241, Total Reward: 69.0\n",
      "Episode: 242, Total Reward: 193.0\n",
      "Episode: 243, Total Reward: 85.0\n",
      "Episode: 244, Total Reward: 154.0\n",
      "Episode: 245, Total Reward: 162.0\n",
      "Episode: 246, Total Reward: 147.0\n",
      "Episode: 247, Total Reward: 179.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 248, Total Reward: 194.0\n",
      "Episode: 249, Total Reward: 190.0\n",
      "Episode: 250, Total Reward: 457.0\n",
      "Episode: 251, Total Reward: 394.0\n",
      "Episode: 252, Total Reward: 180.0\n",
      "Episode: 253, Total Reward: 118.0\n",
      "Episode: 254, Total Reward: 167.0\n",
      "Episode: 255, Total Reward: 209.0\n",
      "Episode: 256, Total Reward: 396.0\n",
      "Episode: 257, Total Reward: 169.0\n",
      "Episode: 258, Total Reward: 191.0\n",
      "Episode: 259, Total Reward: 184.0\n",
      "Episode: 260, Total Reward: 216.0\n",
      "Episode: 261, Total Reward: 500.0\n",
      "Episode: 262, Total Reward: 156.0\n",
      "Episode: 263, Total Reward: 500.0\n",
      "Episode: 264, Total Reward: 436.0\n",
      "Episode: 265, Total Reward: 183.0\n",
      "Episode: 266, Total Reward: 30.0\n",
      "Episode: 267, Total Reward: 184.0\n",
      "Episode: 268, Total Reward: 174.0\n",
      "Episode: 269, Total Reward: 43.0\n",
      "Episode: 270, Total Reward: 147.0\n",
      "Episode: 271, Total Reward: 51.0\n",
      "Episode: 272, Total Reward: 22.0\n",
      "Episode: 273, Total Reward: 471.0\n",
      "Episode: 274, Total Reward: 500.0\n",
      "Episode: 275, Total Reward: 333.0\n",
      "Episode: 276, Total Reward: 178.0\n",
      "Episode: 277, Total Reward: 414.0\n",
      "Episode: 278, Total Reward: 345.0\n",
      "Episode: 279, Total Reward: 500.0\n",
      "Episode: 280, Total Reward: 328.0\n",
      "Episode: 281, Total Reward: 500.0\n",
      "Episode: 282, Total Reward: 496.0\n",
      "Episode: 283, Total Reward: 45.0\n",
      "Episode: 284, Total Reward: 162.0\n",
      "Episode: 285, Total Reward: 153.0\n",
      "Episode: 286, Total Reward: 188.0\n",
      "Episode: 287, Total Reward: 482.0\n",
      "Episode: 288, Total Reward: 190.0\n",
      "Episode: 289, Total Reward: 177.0\n",
      "Episode: 290, Total Reward: 148.0\n",
      "Episode: 291, Total Reward: 136.0\n",
      "Episode: 292, Total Reward: 413.0\n",
      "Episode: 293, Total Reward: 177.0\n",
      "Episode: 294, Total Reward: 500.0\n",
      "Episode: 295, Total Reward: 183.0\n",
      "Episode: 296, Total Reward: 251.0\n",
      "Episode: 297, Total Reward: 144.0\n",
      "Episode: 298, Total Reward: 500.0\n",
      "Episode: 299, Total Reward: 121.0\n",
      "Episode: 300, Total Reward: 238.0\n",
      "Episode: 301, Total Reward: 500.0\n",
      "Episode: 302, Total Reward: 182.0\n",
      "Episode: 303, Total Reward: 242.0\n",
      "Episode: 304, Total Reward: 259.0\n",
      "Episode: 305, Total Reward: 209.0\n",
      "Episode: 306, Total Reward: 169.0\n",
      "Episode: 307, Total Reward: 384.0\n",
      "Episode: 308, Total Reward: 195.0\n",
      "Episode: 309, Total Reward: 267.0\n",
      "Episode: 310, Total Reward: 147.0\n",
      "Episode: 311, Total Reward: 43.0\n",
      "Episode: 312, Total Reward: 257.0\n",
      "Episode: 313, Total Reward: 223.0\n",
      "Episode: 314, Total Reward: 293.0\n",
      "Episode: 315, Total Reward: 168.0\n",
      "Episode: 316, Total Reward: 180.0\n",
      "Episode: 317, Total Reward: 172.0\n",
      "Episode: 318, Total Reward: 44.0\n",
      "Episode: 319, Total Reward: 199.0\n",
      "Episode: 320, Total Reward: 163.0\n",
      "Episode: 321, Total Reward: 32.0\n",
      "Episode: 322, Total Reward: 35.0\n",
      "Episode: 323, Total Reward: 196.0\n",
      "Episode: 324, Total Reward: 344.0\n",
      "Episode: 325, Total Reward: 159.0\n",
      "Episode: 326, Total Reward: 201.0\n",
      "Episode: 327, Total Reward: 39.0\n",
      "Episode: 328, Total Reward: 131.0\n",
      "Episode: 329, Total Reward: 126.0\n",
      "Episode: 330, Total Reward: 167.0\n",
      "Episode: 331, Total Reward: 203.0\n",
      "Episode: 332, Total Reward: 92.0\n",
      "Episode: 333, Total Reward: 207.0\n",
      "Episode: 334, Total Reward: 176.0\n",
      "Episode: 335, Total Reward: 314.0\n",
      "Episode: 336, Total Reward: 213.0\n",
      "Episode: 337, Total Reward: 352.0\n",
      "Episode: 338, Total Reward: 212.0\n",
      "Episode: 339, Total Reward: 110.0\n",
      "Episode: 340, Total Reward: 205.0\n",
      "Episode: 341, Total Reward: 500.0\n",
      "Episode: 342, Total Reward: 500.0\n",
      "Episode: 343, Total Reward: 500.0\n",
      "Episode: 344, Total Reward: 206.0\n",
      "Episode: 345, Total Reward: 64.0\n",
      "Episode: 346, Total Reward: 500.0\n",
      "Episode: 347, Total Reward: 356.0\n",
      "Episode: 348, Total Reward: 500.0\n",
      "Episode: 349, Total Reward: 125.0\n",
      "Episode: 350, Total Reward: 500.0\n",
      "Episode: 351, Total Reward: 500.0\n",
      "Episode: 352, Total Reward: 244.0\n",
      "Episode: 353, Total Reward: 306.0\n",
      "Episode: 354, Total Reward: 500.0\n",
      "Episode: 355, Total Reward: 305.0\n",
      "Episode: 356, Total Reward: 342.0\n",
      "Episode: 357, Total Reward: 500.0\n",
      "Episode: 358, Total Reward: 484.0\n",
      "Episode: 359, Total Reward: 321.0\n",
      "Episode: 360, Total Reward: 407.0\n",
      "Episode: 361, Total Reward: 300.0\n",
      "Episode: 362, Total Reward: 198.0\n",
      "Episode: 363, Total Reward: 161.0\n",
      "Episode: 364, Total Reward: 158.0\n",
      "Episode: 365, Total Reward: 169.0\n",
      "Episode: 366, Total Reward: 492.0\n",
      "Episode: 367, Total Reward: 144.0\n",
      "Episode: 368, Total Reward: 129.0\n",
      "Episode: 369, Total Reward: 149.0\n",
      "Episode: 370, Total Reward: 143.0\n",
      "Episode: 371, Total Reward: 138.0\n",
      "Episode: 372, Total Reward: 440.0\n",
      "Episode: 373, Total Reward: 295.0\n",
      "Episode: 374, Total Reward: 199.0\n",
      "Episode: 375, Total Reward: 140.0\n",
      "Episode: 376, Total Reward: 129.0\n",
      "Episode: 377, Total Reward: 152.0\n",
      "Episode: 378, Total Reward: 165.0\n",
      "Episode: 379, Total Reward: 135.0\n",
      "Episode: 380, Total Reward: 218.0\n",
      "Episode: 381, Total Reward: 152.0\n",
      "Episode: 382, Total Reward: 500.0\n",
      "Episode: 383, Total Reward: 328.0\n",
      "Episode: 384, Total Reward: 500.0\n",
      "Episode: 385, Total Reward: 146.0\n",
      "Episode: 386, Total Reward: 165.0\n",
      "Episode: 387, Total Reward: 164.0\n",
      "Episode: 388, Total Reward: 455.0\n",
      "Episode: 389, Total Reward: 146.0\n",
      "Episode: 390, Total Reward: 341.0\n",
      "Episode: 391, Total Reward: 151.0\n",
      "Episode: 392, Total Reward: 182.0\n",
      "Episode: 393, Total Reward: 351.0\n",
      "Episode: 394, Total Reward: 167.0\n",
      "Episode: 395, Total Reward: 500.0\n",
      "Episode: 396, Total Reward: 197.0\n",
      "Episode: 397, Total Reward: 294.0\n",
      "Episode: 398, Total Reward: 302.0\n",
      "Episode: 399, Total Reward: 469.0\n",
      "Episode: 400, Total Reward: 408.0\n",
      "Episode: 401, Total Reward: 382.0\n",
      "Episode: 402, Total Reward: 195.0\n",
      "Episode: 403, Total Reward: 201.0\n",
      "Episode: 404, Total Reward: 273.0\n",
      "Episode: 405, Total Reward: 203.0\n",
      "Episode: 406, Total Reward: 500.0\n",
      "Episode: 407, Total Reward: 193.0\n",
      "Episode: 408, Total Reward: 192.0\n",
      "Episode: 409, Total Reward: 220.0\n",
      "Episode: 410, Total Reward: 337.0\n",
      "Episode: 411, Total Reward: 213.0\n",
      "Episode: 412, Total Reward: 251.0\n",
      "Episode: 413, Total Reward: 199.0\n",
      "Episode: 414, Total Reward: 15.0\n",
      "Episode: 415, Total Reward: 198.0\n",
      "Episode: 416, Total Reward: 286.0\n",
      "Episode: 417, Total Reward: 269.0\n",
      "Episode: 418, Total Reward: 194.0\n",
      "Episode: 419, Total Reward: 207.0\n",
      "Episode: 420, Total Reward: 207.0\n",
      "Episode: 421, Total Reward: 500.0\n",
      "Episode: 422, Total Reward: 257.0\n",
      "Episode: 423, Total Reward: 474.0\n",
      "Episode: 424, Total Reward: 294.0\n",
      "Episode: 425, Total Reward: 128.0\n",
      "Episode: 426, Total Reward: 292.0\n",
      "Episode: 427, Total Reward: 440.0\n",
      "Episode: 428, Total Reward: 75.0\n",
      "Episode: 429, Total Reward: 289.0\n",
      "Episode: 430, Total Reward: 187.0\n",
      "Episode: 431, Total Reward: 348.0\n",
      "Episode: 432, Total Reward: 34.0\n",
      "Episode: 433, Total Reward: 34.0\n",
      "Episode: 434, Total Reward: 425.0\n",
      "Episode: 435, Total Reward: 179.0\n",
      "Episode: 436, Total Reward: 500.0\n",
      "Episode: 437, Total Reward: 54.0\n",
      "Episode: 438, Total Reward: 40.0\n",
      "Episode: 439, Total Reward: 135.0\n",
      "Episode: 440, Total Reward: 140.0\n",
      "Episode: 441, Total Reward: 92.0\n",
      "Episode: 442, Total Reward: 500.0\n",
      "Episode: 443, Total Reward: 500.0\n",
      "Episode: 444, Total Reward: 435.0\n",
      "Episode: 445, Total Reward: 132.0\n",
      "Episode: 446, Total Reward: 255.0\n",
      "Episode: 447, Total Reward: 500.0\n",
      "Episode: 448, Total Reward: 221.0\n",
      "Episode: 449, Total Reward: 500.0\n",
      "Episode: 450, Total Reward: 350.0\n",
      "Episode: 451, Total Reward: 500.0\n",
      "Episode: 452, Total Reward: 500.0\n",
      "Episode: 453, Total Reward: 500.0\n",
      "Episode: 454, Total Reward: 500.0\n",
      "Episode: 455, Total Reward: 51.0\n",
      "Episode: 456, Total Reward: 500.0\n",
      "Episode: 457, Total Reward: 181.0\n",
      "Episode: 458, Total Reward: 500.0\n",
      "Episode: 459, Total Reward: 48.0\n",
      "Episode: 460, Total Reward: 500.0\n",
      "Episode: 461, Total Reward: 500.0\n",
      "Episode: 462, Total Reward: 250.0\n",
      "Episode: 463, Total Reward: 500.0\n",
      "Episode: 464, Total Reward: 500.0\n",
      "Episode: 465, Total Reward: 500.0\n",
      "Episode: 466, Total Reward: 222.0\n",
      "Episode: 467, Total Reward: 255.0\n",
      "Episode: 468, Total Reward: 275.0\n",
      "Episode: 469, Total Reward: 298.0\n",
      "Episode: 470, Total Reward: 323.0\n",
      "Episode: 471, Total Reward: 500.0\n",
      "Episode: 472, Total Reward: 500.0\n",
      "Episode: 473, Total Reward: 500.0\n",
      "Episode: 474, Total Reward: 500.0\n",
      "Episode: 475, Total Reward: 494.0\n",
      "Episode: 476, Total Reward: 500.0\n",
      "Episode: 477, Total Reward: 500.0\n",
      "Episode: 478, Total Reward: 500.0\n",
      "Episode: 479, Total Reward: 500.0\n",
      "Episode: 480, Total Reward: 500.0\n",
      "Episode: 481, Total Reward: 500.0\n",
      "Episode: 482, Total Reward: 273.0\n",
      "Episode: 483, Total Reward: 500.0\n",
      "Episode: 484, Total Reward: 500.0\n",
      "Episode: 485, Total Reward: 500.0\n",
      "Episode: 486, Total Reward: 500.0\n",
      "Episode: 487, Total Reward: 500.0\n",
      "Episode: 488, Total Reward: 500.0\n",
      "Episode: 489, Total Reward: 500.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 490, Total Reward: 500.0\n",
      "Episode: 491, Total Reward: 500.0\n",
      "Episode: 492, Total Reward: 500.0\n",
      "Episode: 493, Total Reward: 500.0\n",
      "Episode: 494, Total Reward: 30.0\n",
      "Episode: 495, Total Reward: 500.0\n",
      "Episode: 496, Total Reward: 500.0\n",
      "Episode: 497, Total Reward: 500.0\n",
      "Episode: 498, Total Reward: 500.0\n",
      "Episode: 499, Total Reward: 500.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\core.py:50: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
      "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  \"You are calling render method, \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# SumTree and PrioritizedReplayBuffer class definitions\n",
    "class SumTree:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "        self.data = np.zeros(capacity, dtype=object)\n",
    "        self.size = 0\n",
    "        self.write = 0\n",
    "\n",
    "    def _propagate(self, idx, change):\n",
    "        parent = (idx - 1) // 2\n",
    "        self.tree[parent] += change\n",
    "        if parent != 0:\n",
    "            self._propagate(parent, change)\n",
    "\n",
    "    def _retrieve(self, idx, s):\n",
    "        left = 2 * idx + 1\n",
    "        right = left + 1\n",
    "        if left >= len(self.tree):\n",
    "            return idx\n",
    "        if s <= self.tree[left]:\n",
    "            return self._retrieve(left, s)\n",
    "        else:\n",
    "            return self._retrieve(right, s - self.tree[left])\n",
    "\n",
    "    def total(self):\n",
    "        return self.tree[0]\n",
    "\n",
    "    def add(self, priority, data):\n",
    "        idx = self.write + self.capacity - 1\n",
    "        self.data[self.write] = data\n",
    "        self.update(idx, priority)\n",
    "        self.write += 1\n",
    "        if self.write >= self.capacity:\n",
    "            self.write = 0\n",
    "        if self.size < self.capacity:\n",
    "            self.size += 1\n",
    "\n",
    "    def update(self, idx, priority):\n",
    "        change = priority - self.tree[idx]\n",
    "        self.tree[idx] = priority\n",
    "        self._propagate(idx, change)\n",
    "\n",
    "    def get(self, s):\n",
    "        idx = self._retrieve(0, s)\n",
    "        dataIdx = idx - self.capacity + 1\n",
    "        return idx, self.tree[idx], self.data[dataIdx]\n",
    "\n",
    "class PrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=0.6):\n",
    "        self.tree = SumTree(capacity)\n",
    "        self.capacity = capacity\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def add(self, error, sample):\n",
    "        p = (error + 1e-5) ** self.alpha\n",
    "        self.tree.add(p, sample)\n",
    "\n",
    "    def sample(self, n, beta=0.4):\n",
    "        batch = []\n",
    "        segment = self.tree.total() / n\n",
    "        priorities = []\n",
    "        indices = []\n",
    "        for i in range(n):\n",
    "            s = random.uniform(segment * i, segment * (i + 1))\n",
    "            idx, p, data = self.tree.get(s)\n",
    "            priorities.append(p)\n",
    "            batch.append(data)\n",
    "            indices.append(idx)\n",
    "        sampling_probabilities = priorities / self.tree.total()\n",
    "        is_weight = np.power(self.tree.size * sampling_probabilities, -beta)\n",
    "        is_weight /= is_weight.max()\n",
    "        return batch, indices, is_weight\n",
    "\n",
    "    def update(self, idx, error):\n",
    "        p = (error + 1e-5) ** self.alpha\n",
    "        self.tree.update(idx, p)\n",
    "\n",
    "\n",
    "# QNetwork class definition\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, action_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "def select_action(q_network, state, epsilon, action_dim):\n",
    "    if random.random() < epsilon:\n",
    "        return random.choice(range(action_dim))\n",
    "    else:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            q_values = q_network(state)\n",
    "        return q_values.argmax().item()\n",
    "\n",
    "def train_double_dqn(env, q_network, target_network, optimizer, replay_buffer, batch_size, gamma, beta):\n",
    "    '''\n",
    "    배치 사이즈마다 학습을 진행.우선순위 버퍼에서 샘플 데이터를 골라 온다\n",
    "    현상태에 대해 q네트워크가 행동을 선택하게 하고 q-value를 계산\n",
    "    다음상태에 대해 타겟네트워크의 q-value를 계산 예측하게 한다.\n",
    "    이 차이를 줄이도록 학습시킴\n",
    "    '''\n",
    "    if len(replay_buffer.tree.data) < batch_size:\n",
    "          return\n",
    "    batch, indices, is_weights = replay_buffer.sample(batch_size, beta)\n",
    "    states, actions, rewards, next_states, dones = zip(*batch)\n",
    "    \n",
    "    states = torch.FloatTensor(states)\n",
    "    actions = torch.LongTensor(actions).unsqueeze(1)\n",
    "    rewards = torch.FloatTensor(rewards)\n",
    "    next_states = torch.FloatTensor(next_states)\n",
    "    dones = torch.FloatTensor(dones)\n",
    "    is_weights = torch.FloatTensor(is_weights)\n",
    "    \n",
    "    q_values = q_network(states).gather(1, actions).squeeze()\n",
    "    next_q_values = target_network(next_states).max(1)[0]\n",
    "    expected_q_values = rewards + (gamma * next_q_values * (1 - dones))\n",
    "    \n",
    "    errors = torch.abs(q_values - expected_q_values.detach()).cpu().data.numpy()\n",
    "    for i in range(batch_size):\n",
    "        replay_buffer.update(indices[i], errors[i])\n",
    "        \n",
    "    loss = (is_weights * (q_values - expected_q_values.detach()).pow(2)).mean()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def main():\n",
    "    env = gym.make('CartPole-v1')\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.n\n",
    "\n",
    "    # Double Network : 가치가 때때로 과대평가되는 현상을 방지하고 안정적으로 학습\n",
    "    # q_network : action을 선택할 때는 environment와 상호작용하는 네트워크를 사용\n",
    "    # target_network : 가치를 평가할 때는 environment와 독립된 네트워크를 사용. 배치마다 q_network의 파라미터를 복사받음.\n",
    "    q_network = QNetwork(state_dim, action_dim)\n",
    "    target_network = QNetwork(state_dim, action_dim)\n",
    "    target_network.load_state_dict(q_network.state_dict())\n",
    "\n",
    "    optimizer = optim.Adam(q_network.parameters(), lr=1e-3)\n",
    "    replay_buffer = PrioritizedReplayBuffer(10000) # alpha : 우선순위가 해당 샘플을 선택하는데 관여하는 정도 (0: 모두 랜덤, 1 : 우선순위가 곧 확률)\n",
    "    batch_size = 64 # 학습 갱신 주기\n",
    "    gamma = 0.99 # 현재 즉각적인 보상 대비 미래 예상 보상의 가중치\n",
    "    epsilon = 1.0 # 탐사율\n",
    "    epsilon_decay = 0.99 # 탐사율 감소율\n",
    "    epsilon_min = 0.001 # 최소 탐사율\n",
    "    beta_start = 0.4 # 중요도 대비 최신 데이터의 중요성. 갈수록 1에 가까워지도록\n",
    "    beta_frames = 1000 # 베타의 증가도\n",
    "    beta = beta_start\n",
    "    target_update_frequency = 10\n",
    "\n",
    "    num_episodes = 500\n",
    "    frame_idx = 0\n",
    "\n",
    "    ############################ pseudo code ########################################\n",
    "    # 1. 에피소드 마다\n",
    "\n",
    "    ## 2. 환경 , 보상 초기화\n",
    "    ## 3. 게임이 끝나지 않는 한\n",
    "\n",
    "    ### 4. 베타 조정\n",
    "    ### 5. 행동 선택\n",
    "    ### 6. 선택된 행동 반영후 변화된 환경, 보상, 종료여부를 수집\n",
    "    ### 7. 우선순위 버퍼에 저장\n",
    "    ### 8. 상태와 보상 변경\n",
    "    ### 9. 네트워크 학습\n",
    "\n",
    "    ## 10. 게임 종료시 특정 에피소드마다 네트워크 복사\n",
    "\n",
    "    ############################ pseudo code ########################################\n",
    "\n",
    "\n",
    "    for episode in range(num_episodes): # 1. 에피소드 마다\n",
    "        state = env.reset()  ## 2. 환경 , 보상 초기화\n",
    "        total_reward = 0 ## 3. 게임이 끝나지 않는 한\n",
    "        done = False\n",
    "        while not done:\n",
    "            frame_idx += 1\n",
    "            beta = min(1.0, beta_start + frame_idx * (1.0 - beta_start) / beta_frames) ### 4. 베타 조정\n",
    "            action = select_action(q_network, state, epsilon, action_dim) ### 5. 행동 선택\n",
    "            next_state, reward, done, _ = env.step(action) ### 6. 선택된 행동 반영후 변화된 환경, 보상, 종료여부를 수집\n",
    "            replay_buffer.add(abs(reward), (state, action, reward, next_state, done)) ### 7. 우선순위 버퍼에 저장\n",
    "            state = next_state ### 8. 상태와 보상 변경\n",
    "            total_reward += reward  ### 8. 상태와 보상 변경\n",
    "\n",
    "            train_double_dqn(env, q_network, target_network, optimizer, replay_buffer, batch_size, gamma, beta)  ### 9. 네트워크 학습\n",
    "\n",
    "            if done:\n",
    "                if epsilon > epsilon_min:\n",
    "                    epsilon *= epsilon_decay\n",
    "                print(f\"Episode: {episode}, Total Reward: {total_reward}\")\n",
    "\n",
    "        if episode % target_update_frequency == 0:\n",
    "            target_network.load_state_dict(q_network.state_dict())\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(q_network.state_dict(), 'double_dqn_per_cartpole.pth')\n",
    "\n",
    "    # Load the trained model\n",
    "    q_network.load_state_dict(torch.load('double_dqn_per_cartpole.pth'))\n",
    "\n",
    "    # Evaluation\n",
    "    state = env.reset()\n",
    "    for _ in range(1000):\n",
    "        action = select_action(q_network, state, epsilon=0, action_dim=action_dim)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        env.render()\n",
    "        if done:\n",
    "            state = env.reset()\n",
    "    env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fcb382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
